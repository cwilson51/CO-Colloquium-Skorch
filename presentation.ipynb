{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/logo.svg\" width=\"1000\" height=\"200\">\n",
    "\n",
    "# Training PyTorch models with scikit-learn\n",
    "\n",
    "### Collin Wilson - University of Guelph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "* [What is Skorch?](#What-is-Skorch?)\n",
    "* [Who should use Skorch?](#Who-should-use-Skorch?)\n",
    "* [The Basics - Learning by example](#The-Basics)\n",
    "* [Benchmarks](#Benchmarks:-Skorch-vs-pure-Pytorch)\n",
    "* [More of the basics](#More-of-the-basics)\n",
    "* [Multi GPU accelerated grid search](#Multi-GPU-accelerated-grid-search)\n",
    "* [Other features](#Other-features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Skorch?\n",
    "\n",
    "* Skorch is a wrapper for PyTorch `nn.Module`'s that allows models writen in PyTorch to be trained in `scikit-learn` workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is `scikit-learn`?\n",
    "\n",
    "* one of the most popular general machine learning python packages with tools for splitting data into train/test sets, cross-validation, hyperparameter optimization, creating training pipelines and many more \n",
    "* great for learning the fundamentals of feature engineering, dataset management, model creation and model selection\n",
    "* limited for deep learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is PyTorch?\n",
    "* PyTorch is an extremely popular deep learning python library \n",
    "* supports GPU training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Skorch?\n",
    "\n",
    "* Skorch is a wrapper for PyTorch `nn.Module`'s that allows models writen in PyTorch to be trained in `scikit-learn` workflows <br></br>\n",
    "\n",
    "* Allowing a PyTorch model to be used in the `scikit-learn` workflow reduces the need for boilerplate code:\n",
    "    *  training a model is as simple as `net.fit(X, y)` no need to write code for training, validation, reporting etc. \n",
    "    * **The only thing you need is the model definition** <br></br>\n",
    "* supports accelerated hyperparameter optimization using multiple GPUs<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Who should use Skorch?<br></br>\n",
    "\n",
    "\n",
    "* If you already use `scikit-learn` for machine learning workflows and are wanting to incorporate more complex deep learning models<br></br>\n",
    "* If you are just starting with machine learning and also want to learn how to write deep models in PyTorch <br></br>\n",
    "* If you want to do relatively pain-free, multi-GPU accelerated hyperparameter optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V920LTuiq40d",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# The Basics\n",
    "\n",
    "## Learning by example\n",
    "\n",
    "Modified from [skorch tutorials](https://github.com/skorch-dev/skorch/tree/master/notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZ3Y_KHvq40x",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpsnS1HDq403",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H55IvQdyq403",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# This is a toy dataset for binary classification, 1000 data points with 20 features each\n",
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
    "X, y = X.astype(np.float32), y.astype(np.int64)\n",
    "X.shape, y.shape, y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the dataset after some dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Visiualize the dataset after some PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_X = pca.fit_transform(X)\n",
    "y_str = ['Class ' + str(i) for i in y]\n",
    "fig=px.scatter_3d(x=pca_X[:, 0], y=pca_X[:, 1], z=pca_X[:, 2], color=y_str)\n",
    "fig.update_traces(marker={'size': 3})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w2mm41yq407",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Definition of the `pytorch` classification `module`\n",
    "\n",
    "* Vanilla neural network with two hidden layers. <br></br>\n",
    "* The output layer should have 2 output units since there are two classes. <br></br>\n",
    "* In addition, it should have a softmax nonlinearity, because later, when calling `predict_proba`, the output from the `forward` call will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7eNyYKzq408",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X) \n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN9hYiWvq409",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training\n",
    "\n",
    "We use `NeuralNetClassifier` because we're dealing with a classifcation task. The first argument should be the `pytorch module`. As additional arguments, we pass the number of epochs and the learning rate (`lr`), but those are optional.\n",
    "\n",
    "*Note*: To use the CUDA backend, pass `device='cuda'` as an additional argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14HVaJZDq40-",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "#     device='cuda',  # uncomment this to train with CUDA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNxs9BRJq41A",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As in `sklearn`, we call `fit` passing the input data `X` and the targets `y`. By default, `NeuralNetClassifier` makes a `StratifiedKFold` split on the data (80/20) to track the validation loss. This is shown, as well as the train loss and the accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juu_iujpq41B",
    "outputId": "ed85d9f9-b0f1-4c2f-a8bc-bf6722e54326",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Training the network \n",
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rohwh7Ugq41C",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inference\n",
    "\n",
    "Also, as in `sklearn`, you may call `predict` or `predict_proba` on the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxWtMQCtq41D",
    "outputId": "06030606-bc4e-4396-80ec-d5724af50077",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Making prediction for first 5 data points of X\n",
    "y_pred = net.predict(X[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWqQm6WXq41E",
    "outputId": "59e7af8c-6ba5-432b-f874-9e65ce0d1789",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Checking probarbility of each class for first 5 data points of X\n",
    "y_proba = net.predict_proba(X[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX9F9i9Nq41E",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training other types of models:\n",
    "- `NeuralNetRegressor` for regression\n",
    "- `NeuralNetBinaryClassifier` for binary classification\n",
    "- `NeuralNet` base clase, for more generality/customization possibilities\n",
    "- Also include utilities for Gaussian Process models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Benchmarks: Skorch vs pure Pytorch\n",
    "\n",
    "## 1. Simple Convolutional Neural Network (CNN) on MNIST\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<center><img src=\"images/MnistExamplesModified.png\" style></center>\n",
    "<br><br>\n",
    "\n",
    "\n",
    "By Suvanjanprasai - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=132282871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "durations = pd.read_csv('benchmarks/mnist_benchmark.csv')\n",
    "durations['skorch'] = durations['skorch_t']\n",
    "durations['torch'] = durations['torch_t']\n",
    "\n",
    "mnist_fig = px.line(durations, x=\"epoch\", y=[\"skorch\", \"torch\"], \n",
    "              title=\"Training duration for Skorch and pure PyTorch - CNN on MNIST\")\n",
    "mnist_fig.update_yaxes(title='Wall time (s)')\n",
    "mnist_fig.update_layout(width=1600, height=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2. Resnet32 on CIFAR-10\n",
    "\n",
    "<table>\n",
    "    <tbody><tr>\n",
    "        <td><img src=\"images/resnet.png\" width=\"600\"></td>\n",
    "<td><table>\n",
    "    <tbody><tr>\n",
    "        <td class=\"cifar-class-name\">airplane</td>\n",
    "        <td><img src=\"cifar-10-sample/airplane1.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/airplane2.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/airplane3.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/airplane4.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/airplane5.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/airplane6.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/airplane7.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/airplane8.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/airplane9.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/airplane10.png\" class=\"cifar-sample\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"cifar-class-name\">automobile</td>\n",
    "        <td><img src=\"cifar-10-sample/automobile1.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/automobile2.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/automobile3.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/automobile4.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/automobile5.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/automobile6.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/automobile7.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/automobile8.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/automobile9.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/automobile10.png\" class=\"cifar-sample\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"cifar-class-name\">bird</td>\n",
    "        <td><img src=\"cifar-10-sample/bird1.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/bird2.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/bird3.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/bird4.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/bird5.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/bird6.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/bird7.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/bird8.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/bird9.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/bird10.png\" class=\"cifar-sample\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"cifar-class-name\">cat</td>\n",
    "        <td><img src=\"cifar-10-sample/cat1.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/cat2.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/cat3.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/cat4.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/cat5.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/cat6.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/cat7.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/cat8.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/cat9.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/cat10.png\" class=\"cifar-sample\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"cifar-class-name\">deer</td>\n",
    "        <td><img src=\"cifar-10-sample/deer1.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/deer2.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/deer3.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/deer4.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/deer5.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/deer6.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/deer7.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/deer8.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/deer9.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/deer10.png\" class=\"cifar-sample\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"cifar-class-name\">dog</td>\n",
    "        <td><img src=\"cifar-10-sample/dog1.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/dog2.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/dog3.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/dog4.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/dog5.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/dog6.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/dog7.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/dog8.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/dog9.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/dog10.png\" class=\"cifar-sample\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"cifar-class-name\">frog</td>\n",
    "        <td><img src=\"cifar-10-sample/frog1.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/frog2.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/frog3.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/frog4.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/frog5.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/frog6.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/frog7.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/frog8.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/frog9.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/frog10.png\" class=\"cifar-sample\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"cifar-class-name\">horse</td>\n",
    "        <td><img src=\"cifar-10-sample/horse1.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/horse2.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/horse3.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/horse4.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/horse5.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/horse6.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/horse7.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/horse8.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/horse9.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/horse10.png\" class=\"cifar-sample\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"cifar-class-name\">ship</td>\n",
    "        <td><img src=\"cifar-10-sample/ship1.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/ship2.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/ship3.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/ship4.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/ship5.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/ship6.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/ship7.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/ship8.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/ship9.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/ship10.png\" class=\"cifar-sample\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td class=\"cifar-class-name\">truck</td>\n",
    "        <td><img src=\"cifar-10-sample/truck1.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/truck2.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/truck3.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/truck4.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/truck5.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/truck6.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/truck7.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/truck8.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/truck9.png\" class=\"cifar-sample\"></td>\n",
    "        <td><img src=\"cifar-10-sample/truck10.png\" class=\"cifar-sample\"></td>\n",
    "    </tr></tbody>\n",
    "</table></td></tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Sources: [*Deep Residual Learning for Image Recognition*](https://arxiv.org/pdf/1512.03385.pdf) He et. al. (2015), [*The CIFAR-10 dataset*.](https://www.cs.toronto.edu/~kriz/cifar.html) Alex Krizhevsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "durations = pd.read_csv('benchmarks/cifar10_benchmark.csv')\n",
    "cifar_fig = px.line(durations, x=\"epoch\", y=[\"skorch\", \"torch\"], \n",
    "              title=\"Training duration for Skorch and pure PyTorch - ResNet32 on CIFAR-10\")\n",
    "cifar_fig.update_yaxes(title='Wall time (s)')\n",
    "cifar_fig.update_layout(width=1200, height=700)\n",
    "cifar_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cifar_fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlFZurPUq41Z",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X21MVEqtq41Z",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Adding a new callback to the model is straightforward. Below we show how to add a new callback that determines the area under the ROC (AUC) score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxHK8z4Zq41a",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from skorch.callbacks import EpochScoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrV9YE4sq41b",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "There is a scoring callback in skorch, `EpochScoring`, which we use for this. We have to specify which score to calculate:\n",
    "\n",
    "* Passing a string: This should be a valid `sklearn` metric. For a list of all existing scores, look [here](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).\n",
    "* Passing `None`: If you implement your own `.score` method on your neural net, passing `scoring=None` will tell `skorch` to use that.\n",
    "* Passing a function or callable: If we want to define our own scoring function, we pass a function with the signature `func(model, X, y) -> score`, which is then used.\n",
    "\n",
    "`sklearn` already implements AUC, we just pass the correct string `'roc_auc'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsbHe77Uq41c",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "auc = EpochScoring(scoring='roc_auc', lower_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pz-tGJaeq41e",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Finally, we pass the scoring callback to the `callbacks` parameter as a list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7HFlTkoq41e",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,  \n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    callbacks=[auc],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "...and then call `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhOWx_7Tq41e",
    "outputId": "2ac14ec6-3b4c-4b1f-84e7-676a0dfef1be",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2Z7LBzaq41P",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Saving and loading a model\n",
    "\n",
    "Save and load either the whole model by using pickle or just the learned model parameters by calling `save_params` and `load_params`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZPKIAI4q41Q",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Saving the whole model\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "file_name = '/tmp/mymodel.pkl'\n",
    "\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(net, f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Loading the whole model\n",
    "\n",
    "```python\n",
    "with open(file_name, 'rb') as f:\n",
    "    new_net = pickle.load(f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8QcpcM2q41S",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Saving only the model parameters\n",
    "\n",
    "This only saves and loads the proper `module` parameters, meaning that hyperparameters such as `lr` and `max_epochs` are not saved. Therefore, to load the model, we have to re-initialize it beforehand.\n",
    "\n",
    "```python\n",
    "net.save_params(f_params=file_name)  # a file handler also works\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Loading the model using saved parameters\n",
    "\n",
    "```python\n",
    "# first initialize the model\n",
    "new_net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    ").initialize()\n",
    "\n",
    "# load the parameters into the model\n",
    "new_net.load_params(file_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eF9LrDtxq41X",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Usage with an `sklearn Pipeline`\n",
    "\n",
    "It is possible to put the `NeuralNetClassifier` inside an `sklearn Pipeline`, as you would with any `sklearn` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ernAgNliq41X",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('net', net),\n",
    "])\n",
    "\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdp1dLugq41Y",
    "outputId": "10fc1a21-1c15-42af-cf1e-d9065fad963e",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_proba = pipe.predict_proba(X[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGZJIOCXq41Z"
   },
   "source": [
    "To save the whole pipeline, including the pytorch module, use `pickle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ntHaTTXq41f",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Usage with sklearn `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS_Fo2zRq41g",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Special prefixes\n",
    "\n",
    "- The `NeuralNet` class allows to directly access parameters of the `pytorch module` by using the `module__` prefix. \n",
    "    - e.g. if you defined the `module` to have a `num_units` parameter, you can set it via the `module__num_units` argument. \n",
    "    - **modifiable parameters must be passed to your module's `__init__` function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS_Fo2zRq41g",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The `NeuralNet` class allows to directly access parameters of the `pytorch module` by using the `module__` prefix. \n",
    "    - e.g. if you defined the `module` to have a `num_units` parameter, you can set it via the `module__num_units` argument. \n",
    "    - **modifiable parameters must be passed to your module's `__init__` function**\n",
    "    \n",
    "```python\n",
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10, \n",
    "            nonlin=F.relu,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ntHaTTXq41f",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Usage with sklearn `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS_Fo2zRq41g",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Preamble - Special prefixes\n",
    "\n",
    "- The `NeuralNet` class allows to directly access parameters of the `pytorch module` by using the `module__` prefix. \n",
    "    - e.g. if you defined the `module` to have a `num_units` parameter, you can set it via the `module__num_units` argument. \n",
    "    - **modifiable parameters must be passed to your module's `__init__` function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vW3xlLHfq41h",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- This allows you to set parameters in an `sklearn GridSearchCV` as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9o8HamMq41h",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- In addition to the parameters prefixed by `module__`, you may access a couple of other attributes, such as those of the optimizer by using the `optimizer__` prefix (again, see below). All those special prefixes are stored in the `prefixes_` attribute:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9o8HamMq41h",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In addition to the parameters prefixed by `module__`, you may access a couple of other attributes, such as those of the optimizer by using the `optimizer__` prefix (again, see below). All those special prefixes are stored in the `prefixes_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiEKubsQq41h",
    "outputId": "c3280363-6e4e-4fb6-bfe7-6b4b30a77973",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(', '.join(net.prefixes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7mFj9sfq41h",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Performing a grid search\n",
    "\n",
    "Below we show how to perform a grid search over the learning rate (`lr`), the module's number of hidden units (`module__num_units`), and the module's dropout rate (`module__dropout`).\n",
    "\n",
    "The Basic steps are:\n",
    "1. Define the model\n",
    "2. Define the parameter set to search\n",
    "3. Create the `GridSearchCV` object and perform the search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yWN9gsqq41i",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1. Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "McrqjYv-q41i",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqxJik7Cq41i",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    optimizer__momentum=0.9,\n",
    "    verbose=0, \n",
    "    train_split=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Bkur8xQq41j",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- set the verbosity level to zero (`verbose=0`) to prevent too much print output from being shown. \n",
    "- disable the skorch-internal train-validation split (`train_split=False`) because `GridSearchCV` already splits the training data for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yWN9gsqq41i",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2. Define the parameter set to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RMclj0wq41j",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': [0.05, 0.1],\n",
    "    'module__num_units': [10, 20],\n",
    "    'module__dropout': [0, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yWN9gsqq41i",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 3. Create the `GridSearchCV` object... and perform the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNkU7Zf1q41k"
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yWN9gsqq41i",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### ... and perform the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Thjiwvb4q41k",
    "outputId": "b1690c32-a635-46e7-9c3d-66ab4410479e",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBEqgMYSq41k",
    "outputId": "8914f39b-5df7-4061-a701-3eaa3a1e543c",
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2wFkMO5q41l"
   },
   "source": [
    "**Important note: you could further nest the `NeuralNetClassifier` within an `sklearn Pipeline`, in which case, just prefix the parameter by the name of the net (e.g. `net__module__num_units`).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi GPU accelerated grid search\n",
    "\n",
    "* Hyperparameter tuning takes a long time, the search space can be very large <br></br>\n",
    "\n",
    "* If we can be train multiple models simultaneously, we can greatly cut that search time down. <br></br>\n",
    "\n",
    "* Skorch supports multi-GPU training in `GridsearchCV` using Dask <br></br>\n",
    "\n",
    "* We'll use a two GPU set up running ResNet on CIFAR-10 for the following example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initial setup with Dask\n",
    "\n",
    "* Dask is a python package that can be used to parallelize and scale python libraries like NumPy, Pandas and `scikit-learn`, we also need the `distributed` sub-package \n",
    "    * install them in your virtual environment with `pip install --no-index dask distributed` <br></br>\n",
    "    \n",
    "* We use a Dask to create a parallelization backend for `GridSearchCV` allowing use to use multiple GPUs<br></br>\n",
    "\n",
    "* Before running our python code, we need to run a `dask sceduler` and an instance of `dask worker` for each GPU, the key being we set `CUDA_VISIBLE_DEVICES` for each worker<br></br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Initial setup with Dask\n",
    "\n",
    "* Dask is a python package that can be used to parallelize and scale python libraries like NumPy, Pandas and `scikit-learn`\n",
    "* We use a Dask to create a parallelization backend for `GridSearchCV` allowing use to use multiple GPUs\n",
    "* Before running our python code, we need to run a `dask sceduler` and an instance of `dask worker` for each GPU, the key being we set `CUDA_VISIBLE_DEVICES` for each worker:\n",
    "\n",
    "```bash\n",
    "echo 'Starting scheduler'\n",
    "dask scheduler &\n",
    "sleep 10  # give a buffer to make sure the scheduler is started before starting workers\n",
    "\n",
    "echo 'Scheduler booted, launching workers'\n",
    "CUDA_VISIBLE_DEVICES=0 dask worker 127.0.0.1:8786 --nthreads 1 &\n",
    "sleep 10 # This is just to prevent the outputs from being tangled together\n",
    "CUDA_VISIBLE_DEVICES=1 dask worker 127.0.0.1:8786 --nthreads 1 &\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Quick note on job submission \n",
    "\n",
    "* You need to ask for enough cores in your job script:\n",
    "    * One for the scheduler\n",
    "    * One for each worker (two in our example)\n",
    "    * One for the python process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modifying your python code\n",
    "\n",
    "* We need to make some simple modifications to our code to use the parallel backend:\n",
    "\n",
    "```python\n",
    "\n",
    "# import required parallelization modules\n",
    "from dask.distributed import Client\n",
    "from joblib import parallel_backend\n",
    "\n",
    "...\n",
    "\n",
    "def main(device, batch_size, lr, max_epochs):\n",
    "\n",
    "    client = Client('127.0.0.1:8786')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = get_data()\n",
    "\n",
    "    print(\"\\nTesting skorch performance\")\n",
    "    tic = time.time()\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    net = NeuralNetClassifier(\n",
    "        ResNet,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=torch.optim.Adadelta,\n",
    "        criterion=torch.nn.CrossEntropyLoss,\n",
    "        lr=lr,\n",
    "        device=device,\n",
    "        max_epochs=max_epochs\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        'module__num_blocks': [[3,3,3], [5,5,5], [7,7,7]]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(net, params, scoring='accuracy', cv=5, verbose=3, refit=True)\n",
    "    \n",
    "    with parallel_backend('dask'):\n",
    "        gs.fit(X_train, y_train)\n",
    "    print(gs.cv_results_)\n",
    "\n",
    "    y_pred = gs.best_estimator_.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    time_skorch = time.time() - tic\n",
    "\n",
    "    print(f'Grid search found model with validation score: {gs.best_score_}')\n",
    "    print(f'with parameters: {gs.best_params_}')\n",
    "    print(f'Test score: {score} after {max_epochs} in {time_skorch}s.')\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Running the parallel GridSearchCV\n",
    "\n",
    "```\n",
    "[c7wilson@gra847 ~]$ nvidia-smi\n",
    "Sat Nov 25 13:43:51 2023\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\n",
    "| N/A   61C    P0   129W / 250W |   8910MiB / 12288MiB |    100%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  Tesla P100-PCIE...  On   | 00000000:83:00.0 Off |                    0 |\n",
    "| N/A   60C    P0   130W / 250W |   8620MiB / 12288MiB |    100%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "\n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|    0   N/A  N/A     32553      C   ...lson/skorchEnv/bin/python     8620MiB |\n",
    "|    0   N/A  N/A     32600      C   python                            288MiB |\n",
    "|    1   N/A  N/A     32615      C   ...lson/skorchEnv/bin/python     8618MiB |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! cat docs/parallel-multigpu-13158959.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cat /Users/collinwilson/projects/skorch_talk/docs/parallel-multigpu-13158959.out | grep -v distributed.worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat /Users/collinwilson/projects/skorch_talk/docs/parallel-multigpu-13158959.out | grep CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "### Mean fit time\n",
    "\n",
    "|Model   |Serial|Multi-GPU|\n",
    "|--------|------|---------|\n",
    "|ResNet20|319.4 ± 0.9|340 ± 2|\n",
    "|ResNet32|502.2 ± 0.1|524.8 ± 0.8|\n",
    "|ResNet44|686.33 ± 0.03|711 ±2|\n",
    "\n",
    "### Total Wall-time\n",
    "\n",
    "1.28 hours for our multi-GPU grid search vs 2.21 hours for serial, a **42% reduction in running time**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other features\n",
    "\n",
    "* You can also use [Palladium](https://palladium.readthedocs.io/en/latest/) for parallelism <br></br>\n",
    "* Integrations with [Hugging Face](https://huggingface.co/) (`Accelerate`, `Tokenizers` and `Transformers`) <br></br>\n",
    "* [Support for large language models](https://skorch.readthedocs.io/en/stable/llm.html) -  namely few shot and zero shot classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Q&A</h1></center>\n",
    "\n",
    "<center>Please feel free to reach out to me at collin.wilson@sharcnet.ca</center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "rise": {
   "backimage": "images/background.svg"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd97b8bffa4d3737e84826bc3d37be3046061822757ce35137ab82ad4c5a2016"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
